{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "losses = slim.losses\n",
    "ops = slim.ops\n",
    "import tfndlstm as ndlstm\n",
    "import tfspecs as specs\n",
    "from urllib2 import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downoad the MNIST dataset in HDF5 format if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://www.tmbdev.net/ocrdata-hdf5/mnist.h5\"\n",
    "if not os.path.exists(\"mnist.h5\"):\n",
    "    data = urlopen(url).read()\n",
    "    with open(\"mnist.h5\", \"wb\") as stream:\n",
    "        stream.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset and transform it in standard TensorFlow image batch format (BHWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Dataset = namedtuple(\"Dataset\", \"images classes size\")\n",
    "\n",
    "def loadh5(fname, prefix=\"\"):\n",
    "    h5 = h5py.File(fname)\n",
    "    images = array(h5[prefix+\"images\"], \"f\")\n",
    "    images.shape = images.shape + (1,)\n",
    "    labels = array(h5[prefix+\"labels\"], \"i\")\n",
    "    del h5\n",
    "    return Dataset(images, labels, len(images))\n",
    "    \n",
    "train = loadh5(\"mnist.h5\")\n",
    "test = loadh5(\"mnist.h5\", \"test_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) 0.0 1.0\n",
      "(60000,) 0 9\n",
      "(10000, 28, 28, 1) 0.0 1.0\n",
      "(10000,) 0 9\n"
     ]
    }
   ],
   "source": [
    "def info(dataset):\n",
    "    images = dataset.images\n",
    "    labels = dataset.classes\n",
    "    print images.shape, amin(images), amax(images)\n",
    "    print labels.shape, amin(labels), amax(labels)\n",
    "\n",
    "info(train)\n",
    "info(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the \"long form\" network definition of a simple convolutional network using TensorFlow/Slim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_network(net):\n",
    "    net = slim.conv2d(net, 32, 3)\n",
    "    net = slim.max_pool2d(net, 2)\n",
    "    net = slim.conv2d(net, 64, 3)\n",
    "    net = slim.max_pool2d(net, 2)\n",
    "    net = slim.flatten(net)\n",
    "    net = slim.fully_connected(100)\n",
    "    net = slim.fully_connected(10, activation_fn=None)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `specs` language lets us express the same network more concisely. You can use `model.funcall` just like the `make_network` function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with specs.ops:\n",
    "    model = Cr(32, 3) | Mp(2) | Cr(64, 3) | Mp(2) | Flat | Fr(100) | Fl(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the standard TensorFlow framework for training a network. It's pretty boilerplate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "labels = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "outputs = model.funcall(inputs)\n",
    "\n",
    "targets = tf.one_hot(labels, 10, 1.0, 0.0)\n",
    "loss = tf.reduce_sum(tf.square(targets-tf.nn.sigmoid(outputs)))\n",
    "optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "errors = tf.not_equal(tf.argmax(outputs,1), tf.argmax(targets,1))\n",
    "nerrors = tf.reduce_sum(tf.cast(errors, tf.float32))\n",
    "\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(train=train, bs=20):\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for i in range(0, train.size, bs):\n",
    "        batch_images = train.images[i:i+bs]\n",
    "        batch_classes = train.classes[i:i+bs]\n",
    "        feed_dict = {\n",
    "            inputs: batch_images,\n",
    "            labels: batch_classes,\n",
    "        }\n",
    "        k, _ = sess.run([nerrors, train_op], feed_dict=feed_dict)\n",
    "        total += k\n",
    "        count += len(batch_images)\n",
    "    training_error = total * 1.0 / count\n",
    "    return count, training_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(test=test):\n",
    "    bs = 1000\n",
    "    total = 0\n",
    "    for i in range(0, test.size, bs):\n",
    "        batch_images = test[0][i:i+bs]\n",
    "        batch_classes = test[1][i:i+bs]\n",
    "        feed_dict = {\n",
    "            inputs: batch_images,\n",
    "            labels: batch_classes,\n",
    "        }\n",
    "        k, = sess.run([nerrors], feed_dict=feed_dict)\n",
    "        total += k\n",
    "    test_error = total * 1.0 / test.size\n",
    "    return total, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train for 100 epochs and print the training and test set error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.117633333333 0.0449\n",
      "1 0.0346 0.0262\n",
      "2 0.0233 0.0204\n",
      "3 0.0178666666667 0.0169\n",
      "4 0.0146 0.016\n",
      "5 0.0125 0.0129\n",
      "6 0.0105166666667 0.012\n",
      "7 0.00928333333333 0.0113\n",
      "8 0.00818333333333 0.0106\n",
      "9 0.00725 0.0104\n",
      "10 0.00651666666667 0.01\n",
      "11 0.00586666666667 0.0103\n",
      "12 0.00558333333333 0.0096\n",
      "13 0.00515 0.0094\n",
      "14 0.00473333333333 0.0097\n",
      "15 0.00438333333333 0.0099\n",
      "16 0.00408333333333 0.0098\n",
      "17 0.00395 0.0098\n",
      "18 0.00355 0.0109\n",
      "19 0.0035 0.0095\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    _, training_err = train_epoch()\n",
    "    _, testing_err = evaluate()\n",
    "    print epoch, training_err, testing_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
